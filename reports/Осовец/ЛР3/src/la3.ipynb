{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bd77874",
   "metadata": {},
   "source": [
    "Задание 1. Загрузите данные и создайте бинарную целевую переменную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9b2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('winequality-white.csv', sep=';')\n",
    "print(\"Первые 5 строк данных:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nИнформация о данных:\")\n",
    "print(df.info())\n",
    "\n",
    "# Создание бинарной целевой переменной: good (1) — если качество >= 7, иначе 0\n",
    "df['good'] = (df['quality'] >= 7).astype(int)\n",
    "\n",
    "print(\"\\nРаспределение классов (0 — обычное, 1 — хорошее):\")\n",
    "print(df['good'].value_counts())\n",
    "\n",
    "sns.countplot(x='good', data=df)\n",
    "plt.title('Распределение классов (0 — обычное, 1 — хорошее)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d9be30",
   "metadata": {},
   "source": [
    "Задание 2. Стандартизируйте признаки и разделите выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de9121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Разделение признаков и целевой переменной\n",
    "X = df.drop(columns=['quality', 'good'])\n",
    "y = df['good']\n",
    "\n",
    "# Стандартизация признаков\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Размер обучающей выборки: {X_train.shape[0]}\")\n",
    "print(f\"Размер тестовой выборки: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c124f518",
   "metadata": {},
   "source": [
    "Задание 3. Обучите модели k-NN, Decision Tree и SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00e181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# --- k-NN ---\n",
    "f1_scores_knn = []\n",
    "k_values = range(1, 21)\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_knn = knn.predict(X_test)\n",
    "    f1_scores_knn.append(f1_score(y_test, y_pred_knn))\n",
    "\n",
    "best_k = k_values[np.argmax(f1_scores_knn)]\n",
    "best_f1_knn = max(f1_scores_knn)\n",
    "\n",
    "plt.plot(k_values, f1_scores_knn, marker='o')\n",
    "plt.title('Зависимость F1-score от числа соседей (k)')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('F1-score')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Лучший F1-score для k-NN: {best_f1_knn:.4f} при k = {best_k}\")\n",
    "\n",
    "# --- Decision Tree ---\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "f1_tree = f1_score(y_test, y_pred_tree)\n",
    "print(f\"F1-score для Decision Tree: {f1_tree:.4f}\")\n",
    "\n",
    "# --- SVM ---\n",
    "svm = SVC(kernel='rbf', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "print(f\"F1-score для SVM: {f1_svm:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8945100",
   "metadata": {},
   "source": [
    "Задание 4. Сравните F1-score для каждой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0632c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Модель': ['k-NN', 'Decision Tree', 'SVM'],\n",
    "    'F1-score': [best_f1_knn, f1_tree, f1_svm]\n",
    "})\n",
    "\n",
    "display(results.sort_values(by='F1-score', ascending=False))\n",
    "\n",
    "best_model = results.loc[results['F1-score'].idxmax(), 'Модель']\n",
    "print(f\"Лучшая модель по F1-score: {best_model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f80b41",
   "metadata": {},
   "source": [
    "Задание 5. Определите, какой алгоритм показал лучший баланс между точностью и полнотой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0b641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Разделение признаков и целевой переменной\n",
    "X = df.drop(columns=['quality', 'good'])\n",
    "y = df['good']\n",
    "\n",
    "# Стандартизация признаков\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Размер обучающей выборки: {X_train.shape[0]}\")\n",
    "print(f\"Размер тестовой выборки: {X_test.shape[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

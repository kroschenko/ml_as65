import os
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.decomposition import PCA
import seaborn as sns

# –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å —Ñ–∞–π–ª–æ–º
os.chdir("d:/–£–Ω–∏–≤–µ—Ä/–û–ú–û/–û–ú–û2025/–õ–∞–±–∞3/")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
columns = [
    'area',
    'perimeter',
    'compactness',
    'length_of_kernel',
    'width_of_kernel',
    'asymmetry_coefficient',
    'length_of_kernel_groove',
    'class'
]

df = pd.read_csv("seeds_dataset.txt", delim_whitespace=True, names=columns)

print("üîπ –ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:")
print(df.head())
print("\nüîπ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö:")
print(df.info())
print("\nüîπ –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ–ø—É—Å–∫–∏:")
print(df.isnull().sum())
print("\nüîπ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —á–∏—Å–ª–æ–≤—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º:")
print(df.describe())


# –†–∞–∑–¥–µ–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
X = df.drop('class', axis=1)
y = df['class']

# –†–∞–∑–¥–µ–ª—è–µ–º –≤—ã–±–æ—Ä–∫—É –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é (80% / 20%)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è (–æ–±—É—á–∞–µ–º scaler —Ç–æ–ª—å–∫–æ –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏
knn = KNeighborsClassifier(n_neighbors=5)
tree = DecisionTreeClassifier(random_state=42)
svm = SVC(kernel='rbf', random_state=42)

# –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ
knn.fit(X_train_scaled, y_train)
tree.fit(X_train_scaled, y_train)
svm.fit(X_train_scaled, y_train)

# –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
y_pred_knn = knn.predict(X_test_scaled)
y_pred_tree = tree.predict(X_test_scaled)
y_pred_svm = svm.predict(X_test_scaled)

# –í—ã—á–∏—Å–ª—è–µ–º accuracy –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
acc_knn = accuracy_score(y_test, y_pred_knn)
acc_tree = accuracy_score(y_test, y_pred_tree)
acc_svm = accuracy_score(y_test, y_pred_svm)

# –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
print("–¢–æ—á–Ω–æ—Å—Ç—å (Accuracy) –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏:")
print(f"KNN: {acc_knn:.3f}")
print(f"Decision Tree: {acc_tree:.3f}")
print(f"SVM: {acc_svm:.3f}")

# –û–ø—Ä–µ–¥–µ–ª–∏–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
best_model = max(
    [('KNN', acc_knn), ('Decision Tree', acc_tree), ('SVM', acc_svm)],
    key=lambda x: x[1]
)
print(f"\n–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model[0]} (accuracy = {best_model[1]:.3f})")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è k –æ—Ç 1 –¥–æ 30
k_values = range(1, 31)
accuracies = []

for k in k_values:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train_scaled, y_train)
    y_pred_k = knn.predict(X_test_scaled)
    acc = accuracy_score(y_test, y_pred_k)
    accuracies.append(acc)

# –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫
plt.figure(figsize=(8, 5))
plt.plot(k_values, accuracies, marker='o', linestyle='-', color='blue')
plt.title('–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ KNN –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–æ—Å–µ–¥–µ–π (k)')
plt.xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Å–µ–¥–µ–π (k)')
plt.ylabel('Accuracy')
plt.grid(True)
plt.show()

# –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ k
best_k = k_values[accuracies.index(max(accuracies))]
best_acc = max(accuracies)
print(f"–õ—É—á—à–µ–µ k: {best_k}, Accuracy = {best_acc:.3f}")

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ (–¥–æ–ø—É—Å—Ç–∏–º, KNN —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º k)
best_knn = KNeighborsClassifier(n_neighbors=best_k)
best_knn.fit(X_train_scaled, y_train)
y_pred_best = best_knn.predict(X_test_scaled)

# –ü—Ä–∏–º–µ–Ω—è–µ–º PCA (—É–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–æ 2 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_test_scaled)

# –°—Ç—Ä–æ–∏–º DataFrame –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
pca_df = pd.DataFrame(data=X_pca, columns=['PCA1', 'PCA2'])
pca_df['Predicted class'] = y_pred_best

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
plt.figure(figsize=(8, 6))
sns.scatterplot(
    x='PCA1',
    y='PCA2',
    hue='Predicted class',
    data=pca_df,
    palette='Set1',
    alpha=0.8
)
plt.title('–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ–º—è–Ω –ø–æ—Å–ª–µ PCA (—Ä–∞—Å–∫—Ä–∞—Å–∫–∞ –ø–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º –∫–ª–∞—Å—Å–∞–º)')
plt.xlabel('–ì–ª–∞–≤–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 1')
plt.ylabel('–ì–ª–∞–≤–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 2')
plt.legend(title='–ö–ª–∞—Å—Å –ø—à–µ–Ω–∏—Ü—ã')
plt.show()

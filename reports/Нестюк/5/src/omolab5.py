# -*- coding: utf-8 -*-
"""OMOLab5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bfbkjaiM3YzoUbh4VmcyCP0FVKxSYSGl
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.preprocessing import MinMaxScaler

a = 0.2
b = 0.2
c = 0.06
d = 0.2

input_nodes = 8
hidden_nodes = 3
output_nodes = 1

def generate_function(x):
    return a * np.cos(b * x) + c * np.sin(d * x)

def create_dataset(data, look_back=1):
    X, y = [], []
    for i in range(len(data) - look_back):
        X.append(data[i:(i + look_back)])
        y.append(data[i + look_back])
    return np.array(X), np.array(y)

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

def initialize_weights(input_size, hidden_size, output_size):
    np.random.seed(42)
    W1 = np.random.randn(input_size, hidden_size) * 0.1
    b1 = np.zeros((1, hidden_size))
    W2 = np.random.randn(hidden_size, output_size) * 0.1
    b2 = np.zeros((1, output_size))
    return W1, b1, W2, b2

def forward_propagation(X, W1, b1, W2, b2):
    hidden_input = np.dot(X, W1) + b1
    hidden_output = sigmoid(hidden_input)
    output = np.dot(hidden_output, W2) + b2
    return hidden_output, output

def backward_propagation(X, y, hidden_output, output, W1, W2, b1, b2, learning_rate):
    m = y.shape[0]
    output_error = output - y.reshape(-1, 1)
    d_output = output_error / m

    dW2 = np.dot(hidden_output.T, d_output)
    db2 = np.sum(d_output, axis=0, keepdims=True)

    hidden_error = np.dot(d_output, W2.T)
    d_hidden = hidden_error * sigmoid_derivative(hidden_output)

    dW1 = np.dot(X.T, d_hidden)
    db1 = np.sum(d_hidden, axis=0, keepdims=True)

    W1 -= learning_rate * dW1
    b1 -= learning_rate * db1
    W2 -= learning_rate * dW2
    b2 -= learning_rate * db2

    return W1, b1, W2, b2, np.mean(np.square(output_error))

def train_neural_network(X_train, y_train, epochs=3000, learning_rate=0.01):
    W1, b1, W2, b2 = initialize_weights(input_nodes, hidden_nodes, output_nodes)

    errors = []
    for epoch in range(epochs):
        hidden_output, output = forward_propagation(X_train, W1, b1, W2, b2)

        W1, b1, W2, b2, error = backward_propagation(
            X_train, y_train, hidden_output, output, W1, W2, b1, b2, learning_rate
        )

        errors.append(error)

        if epoch % 200 == 0:
            print(f"Эпоха {epoch}, Ошибка: {error:.6f}")

    return W1, b1, W2, b2, errors

def predict(X, W1, b1, W2, b2):
    _, output = forward_propagation(X, W1, b1, W2, b2)
    return output

if __name__ == "__main__":
    x_values = np.linspace(0, 100, 500)
    y_values = generate_function(x_values)

    scaler = MinMaxScaler(feature_range=(-1, 1))
    y_scaled = scaler.fit_transform(y_values.reshape(-1, 1)).flatten()

    X, y = create_dataset(y_scaled, input_nodes)

    split_ratio = 0.8
    split_index = int(len(X) * split_ratio)

    X_train, X_test = X[:split_index], X[split_index:]
    y_train, y_test = y[:split_index], y[split_index:]

    print(f"Размер обучающей выборки: {X_train.shape}")
    print(f"Размер тестовой выборки: {X_test.shape}")

    W1, b1, W2, b2, errors = train_neural_network(X_train, y_train, epochs=5000, learning_rate=0.1)

    train_predictions = predict(X_train, W1, b1, W2, b2)

    test_predictions = predict(X_test, W1, b1, W2, b2)

    y_train_original = scaler.inverse_transform(y_train.reshape(-1, 1)).flatten()
    train_predictions_original = scaler.inverse_transform(train_predictions).flatten()

    y_test_original = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
    test_predictions_original = scaler.inverse_transform(test_predictions).flatten()

    print("\nРЕЗУЛЬТАТЫ ОБУЧЕНИЯ")

    train_results = pd.DataFrame({
        'Эталонное значение': y_train_original,
        'Полученное значение': train_predictions_original,
        'Отклонение': np.abs(y_train_original - train_predictions_original)
    })

    print(train_results.head(10).round(6))

    print("\nРЕЗУЛЬТАТЫ ПРОГНОЗИРОВАНИЯ")

    test_results = pd.DataFrame({
        'Эталонное значение': y_test_original,
        'Полученное значение': test_predictions_original,
        'Отклонение': np.abs(y_test_original - test_predictions_original)
    })

    print(test_results.head(10).round(6))

    plt.figure(figsize=(15, 12))

    plt.subplot(3, 1, 1)
    time_steps_train = range(len(y_train_original))
    plt.plot(time_steps_train, y_train_original, 'b-', label='Эталонные значения', linewidth=2)
    plt.plot(time_steps_train, train_predictions_original, 'r--', label='Прогноз ИНС', linewidth=1.5)
    plt.title('График прогнозируемой функции на участке обучения')
    plt.xlabel('Временной шаг')
    plt.ylabel('Значение функции')
    plt.legend()
    plt.grid(True)

    plt.subplot(3, 1, 2)
    plt.plot(errors)
    plt.title('Изменение ошибки в зависимости от итерации')
    plt.xlabel('Итерация')
    plt.ylabel('Среднеквадратичная ошибка')
    plt.grid(True)
    plt.yscale('log')


    plt.tight_layout()
    plt.show()